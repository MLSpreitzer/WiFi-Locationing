## THE FOLLOWING IS A WORK IN PROGRESS ## 

####################
## Load Packages ## 
####################
library(readr)
library(caret)
library(C50)
library(doParallel)
library(tidyr)
library(RMariaDB)
library(RMySQL)
library(ggplot2)

## Import data
RAWdata <- read.csv("trainingData.csv")


# Find how many cores are on your machine
detectCores() # Result = 4
# Create Cluster with desired number of cores. Don't use them all! Your computer is running other processes. 
cl <- makeCluster(2)
# Register Cluster
registerDoParallel(cl)
# Confirm how many cores are now "assigned" to R and RStudio
getDoParWorkers() # Result 2 
# Stop Cluster. After performing your tasks, stop your cluster. 
#stopCluster(cl)


####################
## Pre-processing ## 
####################

# Verify data type
str(RAWdata) #19937 observations
str(RAWdata[,1:9])
summary(RAWdata[,1:9]) 

# Missing values? 
is.na(RAWdata) #false

# Basic histogram buildings
ggplot(RAWdata, aes(x=BUILDINGID)) + geom_histogram()

# Identify columns with no variance using nearZeroVar()  
nzvMetrics <- nearZeroVar(RAWdata, saveMetrics = TRUE)
nzvMetrics

# remove columns with no variance using nearZeroVar()  
RAWdata = subset(RAWdata, select = -c(WAP003,WAP004,WAP092,WAP093,WAP094,WAP095,WAP152,WAP158,WAP159,WAP160,WAP215,WAP217,WAP226,WAP227,WAP238,WAP239,WAP240,WAP241) )


#########################
## Feature Engineering ## 
#########################

# Group dataset by building number
FEdata.BLD1 <- RAWdata[RAWdata$BUILDINGID == 0, ]
FEdata.BLD2 <- RAWdata[RAWdata$BUILDINGID == 1, ]
FEdata.BLD3 <- RAWdata[RAWdata$BUILDINGID == 2, ]


## ----- option 1 ----- ##
## Loc_UID contains 735 levels

# Combine BUILDINGID, FLOOR, SPACEID 
FEdata <- unite(RAWdata, "Loc_UID", remove = TRUE, sep = ".", c("BUILDINGID","FLOOR", "SPACEID"))
Location1_Bld1 <- unite(FEdata.BLD1, "Loc_UID", remove = TRUE, sep = ".", c("BUILDINGID","FLOOR", "SPACEID"))
Location1_Bld2 <- unite(FEdata.BLD2, "Loc_UID", remove = TRUE, sep = ".", c("BUILDINGID","FLOOR", "SPACEID"))
Location1_Bld3 <- unite(FEdata.BLD3, "Loc_UID", remove = TRUE, sep = ".", c("BUILDINGID","FLOOR", "SPACEID"))

# Convert Loc_UID to factor 
FEdata$Loc_UID <- as.factor(FEdata$Loc_UID)
Location1_Bld1$Loc_UID <- as.factor(Location1_Bld1$Loc_UID)
Location1_Bld2$Loc_UID <- as.factor(Location1_Bld2$Loc_UID)
Location1_Bld3$Loc_UID <- as.factor(Location1_Bld3$Loc_UID)

# verify UID data type
str(FEdata[,1:9])


# Remove unneccasry columns
FEdata = subset(FEdata, select = -c(LONGITUDE,LATITUDE,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location1_Bld1 = subset(Location1_Bld1, select = -c(LONGITUDE,LATITUDE,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location1_Bld2 = subset(Location1_Bld2, select = -c(LONGITUDE,LATITUDE,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location1_Bld3 = subset(Location1_Bld3, select = -c(LONGITUDE,LATITUDE,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )


## ----- option 2  ----- ##
## Loc_UID2 contains 933 levels

# Combine LONGITUDE, LATITUDE, Floor 
FEdata2 <- unite(RAWdata, "Loc_UID2", remove = TRUE, sep = ".", c("LONGITUDE","LATITUDE", "FLOOR"))
Location2_Bld1 <- unite(FEdata.BLD1, "Loc_UID2", remove = TRUE, sep = ".", c("LONGITUDE","LATITUDE", "FLOOR"))
Location2_Bld2 <- unite(FEdata.BLD2, "Loc_UID2", remove = TRUE, sep = ".", c("LONGITUDE","LATITUDE", "FLOOR"))
Location2_Bld3 <- unite(FEdata.BLD3, "Loc_UID2", remove = TRUE, sep = ".", c("LONGITUDE","LATITUDE", "FLOOR"))

# Convert Loc_UID2 to factor 
FEdata2$Loc_UID2 <- as.factor(FEdata2$Loc_UID2)
Location2_Bld1$Loc_UID2 <- as.factor(Location2_Bld1$Loc_UID2)
Location2_Bld2$Loc_UID2 <- as.factor(Location2_Bld2$Loc_UID2)
Location2_Bld3$Loc_UID2 <- as.factor(Location2_Bld3$Loc_UID2)

# verify data type
str(FEdata2[,1:9])

# Remove unneccasry columns
FEdata2 = subset(FEdata2, select = -c(BUILDINGID,SPACEID,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location2_Bld1 = subset(Location2_Bld1, select = -c(BUILDINGID,SPACEID,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location2_Bld2 = subset(Location2_Bld2, select = -c(BUILDINGID,SPACEID,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )
Location2_Bld3 = subset(Location2_Bld3, select = -c(BUILDINGID,SPACEID,RELATIVEPOSITION,USERID,PHONEID,TIMESTAMP) )


## option 2 [Loc_UID2] has more levels (more precision) and we will use it instead of option 1. 

###############
## Modeling ## 
###############

# --- All 3 building RF -- #

# TTS 1 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(FEdata2)*0.7) 
testSize<-nrow(FEdata2)-trainSize
trainSize # 13956
testSize # 5981
training_indices<-sample(seq_len(nrow(FEdata2)),size =trainSize)
trainSet<-FEdata2[training_indices,]
testSet<-FEdata2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(rfFitBuild <- train(Loc_UID2~., data = trainSet, method = "rf", trControl=fitControl, tuneLength = 1))
# Run time 2.7 hours

#training results
rfFitBuild


# %%%%%%%%%%%%  Predict Model 1 RF %%%%%%%%%%%% 

rfPred <- predict(rfFitBuild, newdata = testSet)
#To see the initial row of the predicited data
head(rfPred)
summary(rfFitBuild)

#To determine how the model prioritized each feature
varImp(rfFitBuild) # most important -- [WAP501]

rfClasses_i <- predict(rfFitBuild, newdata = testSet)
str(rfClasses_i)

postResample(rfPred, testSet$Loc_UID2)
# Accuracy     Kappa 
# 0.7965223   0.7962457
summary(rfPred)
plot(rfPred)

# --- Building 1 RF -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld1)*0.8) 
testSize<-nrow(Location2_Bld1)-trainSize
trainSize # 4199
testSize # 1050
training_indices<-sample(seq_len(nrow(Location2_Bld1)),size =trainSize)
trainSet<-Location2_Bld1[training_indices,]
testSet<-Location2_Bld1[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(rfFitBld1 <- train(Loc_UID2~., data = trainSet, method = "rf", trControl=fitControl, tuneLength = 1))
# Run time: 17 minutes

# Accuracy     Kappa 
# 0.7677928  0.7667815

#training results
rfFitBld1


# %%%%%%%%%%%%  Predict Model RF %%%%%%%%%%%% 

rfPredBLD1 <- predict(rfFitBld1, newdata = testSet)
#To see the initial row of the predicited data
head(rfPredBLD1)
summary(rfFitBld1)

#To determine how the model prioritized each feature
varImp(rfFitBld1) # most important -- [WAP501]

rfClassesBLD1 <- predict(rfFitBld1, newdata = testSet)
str(rfClassesBLD1)

postResample(rfPredBLD1, testSet$Loc_UID2)
# Accuracy     Kappa 
# 0.7704762 0.7694471 
summary(rfPredBLD1)
plot(rfPredBLD1)


# --- Building 2 RF -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld2)*0.8) 
testSize<-nrow(Location2_Bld2)-trainSize
trainSize # 4157
testSize # 1039
training_indices<-sample(seq_len(nrow(Location2_Bld2)),size =trainSize)
trainSet<-Location2_Bld2[training_indices,]
testSet<-Location2_Bld2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(rfFitBld2 <- train(Loc_UID2~., data = trainSet, method = "rf", trControl=fitControl, tuneLength = 1))
# Run time: 22  minutes

# Accuracy     Kappa 
# 0.8487728  0.847977

#training results
rfFitBld2


# %%%%%%%%%%%%  Predict Model 2 RF %%%%%%%%%%%% 

rfPredBLD2 <- predict(rfFitBld2, newdata = testSet)
#To see the initial row of the predicited data
head(rfPredBLD2)
summary(rfFitBld2)

#To determine how the model prioritized each feature
varImp(rfFitBld2) # most important -- [WAP501]

rfClassesBLD2 <- predict(rfFitBld2, newdata = testSet)
str(rfClassesBLD2)

postResample(rfPredBLD2, testSet$Loc_UID2)
# Accuracy     Kappa 
#0.8487728  0.847977
summary(rfPredBLD2)
plot(rfPredBLD2)


# --- Building 3 RF -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld3)*0.8) 
testSize<-nrow(Location2_Bld3)-trainSize
trainSize # 7594
testSize # 1898
training_indices<-sample(seq_len(nrow(Location2_Bld3)),size =trainSize)
trainSet<-Location2_Bld3[training_indices,]
testSet<-Location2_Bld3[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(rfFitBld3 <- train(Loc_UID2~., data = trainSet, method = "rf", trControl=fitControl, tuneLength = 1))
# Run time: 45 minutes

# Accuracy     Kappa 
# 0.8142142  0.8136415

#training results
rfFitBld3

# %%%%%%%%%%%%  Predict Model 3 RF %%%%%%%%%%%% 

rfPredBLD3 <- predict(rfFitBld3, newdata = testSet)
#To see the initial row of the predicited data
head(rfPredBLD3)
summary(rfFitBld3)

#To determine how the model prioritized each feature
varImp(rfFitBld3) # most important -- [WAP501]

rfClassesBLD3 <- predict(rfFitBld3, newdata = testSet)
str(rfClassesBLD3)

postResample(rfPredBLD3, testSet$Loc_UID2)
# Accuracy     Kappa 
# 0.8113804 0.8107842 
summary(rfPredBLD3)
plot(rfPredBLD3)

#-----------------------------------------------------------------

# --- All 3 building c5 -- #

# TTS 1 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(FEdata2)*0.7) 
testSize<-nrow(FEdata2)-trainSize
trainSize # 13956
testSize # 5981
training_indices<-sample(seq_len(nrow(FEdata2)),size =trainSize)
trainSet<-FEdata2[training_indices,]
testSet<-FEdata2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(c5FitBuild <- train(Loc_UID2~., data = trainSet, method = "C5.0", trControl=fitControl, tuneLength = 1))
# Run time  15 minutes

# Accuracy     Kappa 
#0.5845119  0.5839530

#training results
c5FitBuild


# %%%%%%%%%%%%  Predict Model 1 c5 %%%%%%%%%%%% 

c5Pred <- predict(c5FitBuild, newdata = testSet)
#To see the initial row of the predicited data
head(c5Pred)
summary(c5FitBuild)

#To determine how the model prioritized each feature
varImp(c5FitBuild) # most important -- [WAP501]

rfClasses_i <- predict(c5FitBuild, newdata = testSet)
str(c5Classes_i)

postResample(c5Pred, testSet$Loc_UID2)
# Accuracy     Kappa 
#0.5895335 0.5889930 
summary(c5Pred)
plot(c5Pred)

# --- Building 1 C5.0 -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld1)*0.8) 
testSize<-nrow(Location2_Bld1)-trainSize
trainSize # 4199
testSize # 1050
training_indices<-sample(seq_len(nrow(Location2_Bld1)),size =trainSize)
trainSet<-Location2_Bld1[training_indices,]
testSet<-Location2_Bld1[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(c5FitBld1 <- train(Loc_UID2~., data = trainSet, method = "C5.0", trControl=fitControl, tuneLength = 1))
# Run time: 2 minutes

# Accuracy     Kappa 
#0.5780753  0.5762808

#training results
c5FitBld1


# %%%%%%%%%%%%  Predict Model c5 %%%%%%%%%%%% 

c5PredBLD1 <- predict(c5FitBld1, newdata = testSet)
#To see the initial row of the predicited data
head(c5PredBLD1)
summary(c5FitBld1)

#To determine how the model prioritized each feature
varImp(c5FitBld1) # most important -- [WAP501]

c5ClassesBLD1 <- predict(c5FitBld1, newdata = testSet)
str(c5ClassesBLD1)

postResample(c5PredBLD1, testSet$Loc_UID2)
# Accuracy     Kappa 
#0.7704762 0.7694471 
summary(c5PredBLD1)
plot(c5PredBLD1)


# --- Building 2 c5 -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld2)*0.8) 
testSize<-nrow(Location2_Bld2)-trainSize
trainSize # 4157
testSize # 1039
training_indices<-sample(seq_len(nrow(Location2_Bld2)),size =trainSize)
trainSet<-Location2_Bld2[training_indices,]
testSet<-Location2_Bld2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(c5FitBld2 <- train(Loc_UID2~., data = trainSet, method = "C5.0", trControl=fitControl, tuneLength = 1))
# Run time:  2 minutes

# Accuracy     Kappa 
#0.6892071  0.6875879

#training results
c5FitBld2


# %%%%%%%%%%%%  Predict Model 2 c5 %%%%%%%%%%%% 

c5PredBLD2 <- predict(c5FitBld2, newdata = testSet)
#To see the initial row of the predicited data
head(c5PredBLD2)
summary(c5FitBld2)

#To determine how the model prioritized each feature
varImp(c5FitBld2) # most important -- [WAP501]

c5ClassesBLD2 <- predict(c5FitBld2, newdata = testSet)
str(c5ClassesBLD2)

postResample(c5PredBLD2, testSet$Loc_UID2)
# Accuracy     Kappa 
#0.7054860 0.7038425 

summary(c5PredBLD2)
plot(c5PredBLD2)


# --- Building 3 c5 -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld3)*0.8) 
testSize<-nrow(Location2_Bld3)-trainSize
trainSize # 7594
testSize # 1898
training_indices<-sample(seq_len(nrow(Location2_Bld3)),size =trainSize)
trainSet<-Location2_Bld3[training_indices,]
testSet<-Location2_Bld3[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(c5FitBld3 <- train(Loc_UID2~., data = trainSet, method = "C5.0", trControl=fitControl, tuneLength = 1))
# Run time: 5 minutes

# Accuracy     Kappa 
#0.5753771  0.5740953

#training results
c5FitBld3

# %%%%%%%%%%%%  Predict Model 3 c5 %%%%%%%%%%%% 

c5PredBLD3 <- predict(c5FitBld3, newdata = testSet)
#To see the initial row of the predicited data
head(c5PredBLD3)
summary(c5FitBld3)

#To determine how the model prioritized each feature
varImp(c5FitBld3) # most important -- [WAP501]

c5ClassesBLD3 <- predict(c5FitBld3, newdata = testSet)
str(c5ClassesBLD3)

postResample(c5PredBLD3, testSet$Loc_UID2)
# Accuracy     Kappa 
#0.5648051 0.5634856 
summary(c5PredBLD3)
plot(c5PredBLD3)




#-----------------------------------------------------------------

# --- All 3 building KNN -- #

# TTS 1 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(FEdata2)*0.7) 
testSize<-nrow(FEdata2)-trainSize
trainSize # 13956
testSize # 5981
training_indices<-sample(seq_len(nrow(FEdata2)),size =trainSize)
trainSet<-FEdata2[training_indices,]
testSet<-FEdata2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(knnFitBuild <- train(Loc_UID2~., data = trainSet, method = "knn", trControl = train_control)
# Run time   minutes

# Accuracy     Kappa 


#training results
knnFitBuild


# %%%%%%%%%%%%  Predict Model 1 knn %%%%%%%%%%%% 

knnPred <- predict(knnFitBuild, newdata = testSet)
#To see the initial row of the predicited data
head(knnPred)
summary(knnFitBuild)

#To determine how the model prioritized each feature
varImp(knnFitBuild) # most important -- [WAP501]

rfClasses_i <- predict(knnFitBuild, newdata = testSet)
str(knnClasses_i)

postResample(knnPred, testSet$Loc_UID2)
# Accuracy     Kappa 

summary(knnPred)
plot(knnPred)

# --- Building 1 knn --- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld1)*0.8) 
testSize<-nrow(Location2_Bld1)-trainSize
trainSize # 4199
testSize # 1050
training_indices<-sample(seq_len(nrow(Location2_Bld1)),size =trainSize)
trainSet<-Location2_Bld1[training_indices,]
testSet<-Location2_Bld1[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(knnFitBld1 <- train(Loc_UID2~., data = trainSet, method = "knn", trControl = train_control)
# Run time:  minutes

# Accuracy     Kappa 


#training results
knnFitBld1


# %%%%%%%%%%%%  Predict Model c5 %%%%%%%%%%%% 

knnPredBLD1 <- predict(knnFitBld1, newdata = testSet)
#To see the initial row of the predicited data
head(knnPredBLD1)
summary(knnFitBld1)

#To determine how the model prioritized each feature
varImp(knnFitBld1) # most important -- [WAP501]

knnClassesBLD1 <- predict(knnFitBld1, newdata = testSet)
str(knnClassesBLD1)

postResample(knnPredBLD1, testSet$Loc_UID2)
# Accuracy     Kappa 

summary(knnPredBLD1)
plot(knnPredBLD1)


# --- Building 2 knn -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld2)*0.8) 
testSize<-nrow(Location2_Bld2)-trainSize
trainSize # 4157
testSize # 1039
training_indices<-sample(seq_len(nrow(Location2_Bld2)),size =trainSize)
trainSet<-Location2_Bld2[training_indices,]
testSet<-Location2_Bld2[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(knnFitBld2 <- train(Loc_UID2~., data = trainSet, method = "knn", trControl = train_control)
# Run time:   minutes

# Accuracy     Kappa 


#training results
knnFitBld2


# %%%%%%%%%%%%  Predict Model 2 c5 %%%%%%%%%%%% 

knnPredBLD2 <- predict(knnFitBld2, newdata = testSet)
#To see the initial row of the predicited data
head(knnPredBLD2)
summary(knnFitBld2)

#To determine how the model prioritized each feature
varImp(knnFitBld2) # most important -- [WAP501]

knnClassesBLD2 <- predict(knnFitBld2, newdata = testSet)
str(knnClassesBLD2)

postResample(knnPredBLD2, testSet$Loc_UID2)
# Accuracy     Kappa 


summary(knnPredBLD2)
plot(knnPredBLD2)


# --- Building 3 knn -- #

# TTS 2 Y Value = Loc_UID2
set.seed(123)
trainSize<-round(nrow(Location2_Bld3)*0.8) 
testSize<-nrow(Location2_Bld3)-trainSize
trainSize # 7594
testSize # 1898
training_indices<-sample(seq_len(nrow(Location2_Bld3)),size =trainSize)
trainSet<-Location2_Bld3[training_indices,]
testSet<-Location2_Bld3[-training_indices,] 

#10 fold cross validation
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 1)

#train Random Forest Regression model with a tuneLenght = 1 (trains with 1 mtry value for RandomForest)
system.time(knnFitBld3 <- train(Loc_UID2~., data = trainSet, method = "knn", trControl = train_control)
# Run time:  minutes

# Accuracy     Kappa 


#training results
knnFitBld3

# %%%%%%%%%%%%  Predict Model 3 knn %%%%%%%%%%%% 

knnPredBLD3 <- predict(knnFitBld3, newdata = testSet)
#To see the initial row of the predicited data
head(knnPredBLD3)
summary(knnFitBld3)

#To determine how the model prioritized each feature
varImp(knnFitBld3) # most important -- [WAP501]

knnClassesBLD3 <- predict(knnFitBld3, newdata = testSet)
str(knnClassesBLD3)

postResample(knnPredBLD3, testSet$Loc_UID2)
# Accuracy     Kappa 

summary(knnPredBLD3)
plot(knnPredBLD3)
